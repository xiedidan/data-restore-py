#!/usr/bin/env python3
"""
PostgreSQL Table Creation Script

Creates tables in PostgreSQL database using DDL files generated by analyze_sql.py.

Usage:
    python create_tables.py --config config.yaml
    python create_tables.py --config config.yaml --drop-existing
    python create_tables.py --pg-database mydb --config config.yaml
"""

import argparse
import os
import sys
from typing import List

# Add the project root to Python path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from oracle_to_postgres.common.config import (
    Config, add_common_arguments, add_postgresql_arguments, add_table_creation_arguments
)
from oracle_to_postgres.common.logger import Logger, TimedLogger
from oracle_to_postgres.common.database import DatabaseManager, ConnectionInfo
from oracle_to_postgres.common.ddl_manager import DDLManager, DDLFile, DDLExecutionResult
from oracle_to_postgres.common.report import ReportGenerator
from oracle_to_postgres.common.error_handler import ErrorHandler


class TableCreator:
    """Main class for creating PostgreSQL tables from DDL files."""
    
    def __init__(self, config: Config):
        """Initialize the table creator with configuration."""
        self.config = config
        self.logger = Logger(
            log_level=config.logging.level,
            log_file=config.logging.file,
            name="create_tables"
        )
        
        # Initialize database connection
        self.connection_info = ConnectionInfo(
            host=config.postgresql.host,
            port=config.postgresql.port,
            database=config.postgresql.database,
            username=config.postgresql.username,
            password=config.postgresql.password,
            schema=config.postgresql.schema
        )
        
        self.db_manager = DatabaseManager(
            connection_info=self.connection_info,
            logger=self.logger
        )
        
        # Initialize DDL manager
        self.ddl_manager = DDLManager(
            ddl_directory=config.ddl_directory,
            db_manager=self.db_manager,
            logger=self.logger
        )
        
        self.report_generator = ReportGenerator()
        self.error_handler = ErrorHandler(logger=self.logger)
    
    def create_tables(self, drop_existing: bool = False, 
                     stop_on_error: bool = False) -> List[DDLExecutionResult]:
        """
        Create tables from DDL files.
        
        Args:
            drop_existing: Whether to drop existing tables
            stop_on_error: Whether to stop on first error
            
        Returns:
            List of DDLExecutionResult objects
        """
        self.logger.section("Starting Table Creation")
        
        # Test database connection
        if not self._test_database_connection():
            self.logger.error("Database connection test failed. Please check your configuration.")
            return []
        
        # Scan for DDL files
        self.logger.info(f"Scanning DDL directory: {self.config.ddl_directory}")
        ddl_files = self.ddl_manager.scan_ddl_files()
        
        if not ddl_files:
            self.logger.warning("No DDL files found in DDL directory")
            return []
        
        self.logger.info(f"Found {len(ddl_files)} DDL files")
        
        # Display DDL files summary
        self._display_ddl_summary(ddl_files)
        
        # Validate DDL files
        self.logger.subsection("Validating DDL Files")
        valid_ddl_files = self.ddl_manager.validate_ddl_files(ddl_files)
        
        if len(valid_ddl_files) < len(ddl_files):
            invalid_count = len(ddl_files) - len(valid_ddl_files)
            self.logger.warning(f"{invalid_count} DDL files failed validation and will be skipped")
        
        if not valid_ddl_files:
            self.logger.error("No valid DDL files found")
            return []
        
        # Analyze dependencies and sort
        self.logger.subsection("Analyzing Dependencies")
        sorted_ddl_files = self.ddl_manager.analyze_dependencies(valid_ddl_files)
        
        if sorted_ddl_files != valid_ddl_files:
            self.logger.info("DDL files reordered based on dependencies")
        
        # Execute DDL files
        results = []
        
        try:
            with self.db_manager as db:
                results = self.ddl_manager.execute_ddl_files(
                    sorted_ddl_files,
                    drop_existing=drop_existing,
                    stop_on_error=stop_on_error
                )
        except Exception as e:
            self.logger.error(f"Database operation failed: {str(e)}")
            return []
        
        # Generate reports
        self._generate_reports(results)
        
        # Display summary
        self._display_summary(results)
        
        # Cleanup failed tables if requested
        if not stop_on_error:
            failed_results = [r for r in results if not r.success and r.table_created]
            if failed_results:
                self.logger.subsection("Cleaning Up Failed Tables")
                cleanup_count = self.ddl_manager.cleanup_failed_tables(failed_results)
                if cleanup_count > 0:
                    self.logger.info(f"Cleaned up {cleanup_count} failed tables")
        
        return results
    
    def _test_database_connection(self) -> bool:
        """Test database connection and display info."""
        self.logger.info("Testing PostgreSQL connection...")
        
        try:
            if not self.db_manager.test_connection():
                return False
            
            # Get database info
            db_info = self.db_manager.get_database_info()
            
            self.logger.info(f"Database: {db_info.get('current_database', 'unknown')}")
            self.logger.info(f"Schema: {db_info.get('current_schema', 'unknown')}")
            self.logger.info(f"User: {db_info.get('current_user', 'unknown')}")
            self.logger.info(f"Encoding: {db_info.get('server_encoding', 'unknown')}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"Database connection test failed: {str(e)}")
            return False
    
    def _display_ddl_summary(self, ddl_files: List[DDLFile]) -> None:
        """Display summary of DDL files."""
        self.logger.info("DDL Files Summary:")
        
        total_size = sum(f.file_size for f in ddl_files)
        self.logger.info(f"  Total files: {len(ddl_files)}")
        self.logger.info(f"  Total size: {total_size / 1024:.1f} KB")
        
        # Display first few files
        display_count = min(5, len(ddl_files))
        for i, ddl_file in enumerate(ddl_files[:display_count]):
            size_kb = ddl_file.file_size / 1024
            self.logger.info(f"  {i+1}. {ddl_file.table_name} ({size_kb:.1f} KB)")
        
        if len(ddl_files) > display_count:
            self.logger.info(f"  ... and {len(ddl_files) - display_count} more files")
    
    def _generate_reports(self, results: List[DDLExecutionResult]) -> None:
        """Generate execution reports."""
        self.logger.subsection("Generating Reports")
        
        try:
            # Generate execution results CSV report
            csv_path = self.report_generator.generate_execution_report(
                results, "table_creation"
            )
            self.logger.info(f"Generated execution report: {csv_path}")
            
            # Generate summary report
            summary_path = self.report_generator.generate_summary_report(
                results,
                "table_creation_summary.txt",
                "Table Creation Summary"
            )
            self.logger.info(f"Generated summary report: {summary_path}")
            
            # Generate JSON report for programmatic access
            json_path = self.report_generator.generate_json_report(
                results,
                "table_creation_results.json"
            )
            self.logger.info(f"Generated JSON report: {json_path}")
            
        except Exception as e:
            self.logger.error(f"Error generating reports: {str(e)}")
    
    def _display_summary(self, results: List[DDLExecutionResult]) -> None:
        """Display execution summary."""
        self.logger.subsection("Table Creation Summary")
        
        summary = self.ddl_manager.get_execution_summary(results)
        
        self.logger.info(f"Total DDL files processed: {summary['total_files']}")
        self.logger.info(f"Tables created successfully: {summary['successful']}")
        self.logger.info(f"Failed table creations: {summary['failed']}")
        
        if summary['total_files'] > 0:
            self.logger.info(f"Success rate: {summary['success_rate']:.1f}%")
        
        self.logger.info(f"Tables created: {summary['tables_created']}")
        self.logger.info(f"Tables dropped: {summary['tables_dropped']}")
        self.logger.info(f"Total execution time: {summary['total_execution_time']:.2f} seconds")
        
        if summary['total_files'] > 0:
            avg_time = summary['average_execution_time']
            self.logger.info(f"Average execution time per table: {avg_time:.2f} seconds")
        
        # Display failed tables
        failed_results = [r for r in results if not r.success]
        if failed_results:
            self.logger.warning("Failed table creations:")
            for result in failed_results[:10]:  # Show first 10 failures
                self.logger.warning(f"  {result.table_name}: {result.error_message}")
            
            if len(failed_results) > 10:
                self.logger.warning(f"  ... and {len(failed_results) - 10} more failures")
        
        # Display error summary
        error_summary = self.error_handler.get_error_summary()
        if error_summary['total_errors'] > 0:
            self.logger.warning(f"Total errors encountered: {error_summary['total_errors']}")
            self.logger.warning(f"Total retries performed: {error_summary['total_retries']}")


def create_argument_parser() -> argparse.ArgumentParser:
    """Create command line argument parser."""
    parser = argparse.ArgumentParser(
        description="Create PostgreSQL tables from DDL files",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python create_tables.py --config config.yaml
  python create_tables.py --config config.yaml --drop-existing
  python create_tables.py --pg-database mydb --config config.yaml
  python create_tables.py --config config.yaml --pg-schema custom_schema
  python create_tables.py --config config.yaml --stop-on-error --log-level DEBUG
        """
    )
    
    # Add argument groups
    add_common_arguments(parser)
    add_postgresql_arguments(parser)
    add_table_creation_arguments(parser)
    
    # Script-specific arguments
    parser.add_argument(
        '--ddl-directory',
        type=str,
        default='./ddl',
        help='Directory containing DDL files (default: ./ddl)'
    )
    

    
    return parser


def main():
    """Main entry point."""
    parser = create_argument_parser()
    args = parser.parse_args()
    
    try:
        # Load configuration
        config = Config.from_args(args)
        
        # Merge with file configuration if exists
        if os.path.exists(args.config):
            config = config.merge_with_file(args.config)
        
        # Override DDL directory if specified
        if args.ddl_directory:
            config.ddl_directory = args.ddl_directory
        
        # Validate configuration (skip DeepSeek API validation for this script)
        try:
            config.validate()
        except ValueError as e:
            # Allow missing DeepSeek API key for table creation
            if "DeepSeek API key" not in str(e):
                raise
        
        # Validate PostgreSQL configuration specifically
        if not config.postgresql.database:
            raise ValueError("PostgreSQL database name is required")
        if not config.postgresql.username:
            raise ValueError("PostgreSQL username is required")
        
        # Handle dry run
        if config.table_creation.dry_run:
            print("DRY RUN MODE - No tables will be created")
            
            # Just scan and display DDL files
            from oracle_to_postgres.common.ddl_manager import DDLManager
            from oracle_to_postgres.common.logger import Logger
            
            logger = Logger()
            ddl_manager = DDLManager(config.ddl_directory, None, logger)
            ddl_files = ddl_manager.scan_ddl_files()
            
            print(f"\nFound {len(ddl_files)} DDL files:")
            for ddl_file in ddl_files:
                print(f"  - {ddl_file.table_name} ({ddl_file.file_name})")
            
            if config.table_creation.drop_existing:
                print("\nWould drop existing tables before creation")
            
            return
        
        # Create table creator and run
        creator = TableCreator(config)
        
        # Debug: Show configuration values
        creator.logger.info(f"Table creation configuration:")
        creator.logger.info(f"  drop_existing: {config.table_creation.drop_existing}")
        creator.logger.info(f"  stop_on_error: {config.table_creation.stop_on_error}")
        creator.logger.info(f"  dry_run: {config.table_creation.dry_run}")
        creator.logger.info(f"PostgreSQL configuration:")
        creator.logger.info(f"  database: {config.postgresql.database}")
        creator.logger.info(f"  schema: {config.postgresql.schema}")
        creator.logger.info(f"  host: {config.postgresql.host}")
        creator.logger.info(f"  port: {config.postgresql.port}")
        
        with TimedLogger(creator.logger, "Table creation"):
            results = creator.create_tables(
                drop_existing=config.table_creation.drop_existing,
                stop_on_error=config.table_creation.stop_on_error
            )
        
        # Exit with appropriate code
        if not results:
            creator.logger.error("No tables were processed")
            sys.exit(1)
        
        successful_count = sum(1 for r in results if r.success)
        
        if successful_count == 0:
            creator.logger.error("No tables were created successfully")
            sys.exit(1)
        elif successful_count < len(results):
            creator.logger.warning(f"Some tables failed to create ({len(results) - successful_count} failures)")
            sys.exit(2)
        else:
            creator.logger.info("All tables created successfully")
            sys.exit(0)
            
    except KeyboardInterrupt:
        print("\nOperation cancelled by user")
        sys.exit(130)
    except Exception as e:
        print(f"Error: {str(e)}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()